# v1.3.0 Specification: Real-time Streaming + True Multi-Model Debates

**Version:** 1.3.0
**Created:** 2026-01-04
**Status:** Draft

---

## Feature Overview

Add real-time streaming output to debates and enable true multi-model debates
using real Claude (when available) instead of simulated perspectives.

### Problem Statement

Current architecture has two issues:

1. **No Real Claude**: Neither orchestrator uses actual Claude
   - `ParallelDebateOrchestrator`: Both "Claude" and "Codex" call Codex CLI
   - `AIOrchestrator`: Claude side is a static template with placeholders

2. **No Streaming**: User waits 10-18 seconds with no feedback

3. **Missed Opportunity**: When running in Claude Code, Claude is available but not used

---

## User Stories

### US-1: Real-time Streaming
As a user running debates via CLI, I want to see live progress updates
so I don't wonder if the tool is working during the 10-18 second wait.

### US-2: True Multi-Model Debates
As a user running debates inside Claude Code, I want the debate to use
actual Claude for analysis (instead of fake templates) so I get genuine
AI-vs-AI perspective comparison.

### US-3: JSON Streaming for Automation
As a developer integrating the tool, I want machine-readable streaming
output so I can build UIs and automation around debate progress.

---

## Acceptance Criteria

### AC-1: CLI Streaming Flag
- [ ] `ai-debate run --stream` shows live progress
- [ ] Progress indicators for each perspective (e.g., "[Claude] Analyzing...")
- [ ] Completion time displayed per perspective (e.g., "Complete (2.3s)")
- [ ] Final consensus shown after both complete

### AC-2: JSON Streaming Flag
- [ ] `ai-debate run --json-stream` outputs JSON lines
- [ ] Events: start, progress, perspective, consensus, complete
- [ ] Each event includes timestamp
- [ ] Can be piped to other tools

### AC-3: MCP Two-Phase Workflow
- [ ] New `debate_start` tool returns prompt for Claude analysis
- [ ] New `debate_complete` accepts Claude's analysis, invokes Codex, returns consensus
- [ ] Real Claude analysis used (not fake template)
- [ ] Existing tools (`debate_start_auto`) continue to work (backward compatible)

### AC-4: Backward Compatibility
- [ ] Default behavior (no flags) unchanged
- [ ] Existing MCP tools still work
- [ ] No breaking changes to Python API

---

## Technical Approach

### New Files

| File | Purpose |
|------|---------|
| `services/model_provider.py` | Abstract provider interface + CodexCLI, CopilotBridge implementations |
| `services/stream_events.py` | StreamEvent dataclass and event types |
| `services/streaming_orchestrator.py` | Async streaming debate orchestration |

### Modified Files

| File | Changes |
|------|---------|
| `mcp_server/debate_server.py` | Add `debate_start`, `debate_complete` tools |
| `services/ai_orchestrator.py` | Support two-phase workflow |
| `cli.py` | Add `--stream` and `--json-stream` flags |
| `__init__.py` | Bump version to 1.3.0, export new classes |

### Architecture

```
                    CLI Command
                        │
                        ▼
                ┌───────────────┐
                │   --stream?   │
                └───────┬───────┘
                        │
           ┌────────────┴────────────┐
           │                         │
           ▼                         ▼
    StreamingOrchestrator    ParallelOrchestrator
           │                         │
           │ (yields events)         │ (returns result)
           │                         │
           ▼                         ▼
    ┌─────────────┐           ┌─────────────┐
    │ ModelProvider          │ ModelProvider│
    │ (parallel)  │           │ (parallel)  │
    └─────────────┘           └─────────────┘
```

### MCP Two-Phase Flow

```
Phase 1: User → debate_start(request, files)
         ← Returns: { session_id, claude_prompt, instructions }

         Claude Code reads prompt, provides REAL analysis

Phase 2: User → debate_complete(session_id, claude_analysis)
         Tool invokes Codex CLI internally
         ← Returns: { consensus_score, decision_pack }
```

---

## Dependencies

- No new Python dependencies required
- Uses existing Codex CLI integration (`codex_cli_invoker.py`)
- Uses existing Copilot Bridge integration (`copilot_invoker.py`)
- Uses existing MCP server infrastructure

---

## Testing Strategy

### Unit Tests
- StreamEvent serialization/deserialization
- ModelProvider interface implementations
- Provider detection logic

### Integration Tests
- Full streaming flow with mock providers
- CLI streaming output verification
- Two-phase MCP workflow

### Manual Tests
- Test in Claude Code environment (real Claude + Codex)
- Test in VS Code with Copilot Bridge
- Test standalone CLI (Codex + Codex fallback)

---

## UI/UX Examples

### Streaming CLI Output
```
$ ai-debate run "Refactor auth" --file auth.py --stream

Starting debate: Refactor auth
File: auth.py (245 lines)

[Claude] Analyzing... ████████░░░░░░░░ 50%
[Codex]  Analyzing... ██████████████░░ 85%

[Claude] Complete (2.3s) → Score: 78/100
[Codex]  Complete (3.1s) → Score: 82/100

Calculating consensus...

═══════════════════════════════════════
RESULT: Consensus 80/100 - PROCEED
═══════════════════════════════════════
```

### JSON Streaming Output
```json
{"type": "start", "timestamp": 1704326400.0, "data": {"request": "Refactor auth", "file": "auth.py"}}
{"type": "progress", "timestamp": 1704326401.5, "data": {"perspective": "claude", "percent": 50}}
{"type": "progress", "timestamp": 1704326402.0, "data": {"perspective": "codex", "percent": 85}}
{"type": "perspective", "timestamp": 1704326402.3, "data": {"name": "claude", "score": 78, "time": 2.3}}
{"type": "perspective", "timestamp": 1704326403.1, "data": {"name": "codex", "score": 82, "time": 3.1}}
{"type": "complete", "timestamp": 1704326403.5, "data": {"consensus": 80, "recommendation": "PROCEED"}}
```

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Codex CLI unavailable | Debate fails | Graceful error message, suggest installation |
| MCP two-phase timing issues | Confusing UX | Clear instructions in tool response |
| Streaming breaks in certain terminals | Bad UX | Fallback to simple text if TTY detection fails |

---

## Estimated Effort

| Component | Effort |
|-----------|--------|
| Model Provider Interface | 2-3 hours |
| Stream Events Module | 30 min |
| Streaming Orchestrator | 2-3 hours |
| MCP Two-Phase Tools | 2 hours |
| CLI Updates | 1-2 hours |
| Tests | 2-3 hours |
| Documentation | 1 hour |
| **Total** | **~10-14 hours** |

---

## Release Notes Draft

```markdown
## v1.3.0 - Real-time Streaming + Multi-Model Debates

### New Features

- **Streaming Output**: See live progress during debates with `--stream` flag
- **JSON Streaming**: Machine-readable event stream with `--json-stream`
- **True Multi-Model (MCP)**: New two-phase workflow uses real Claude for analysis

### New MCP Tools

- `debate_start`: Start debate, get prompt for Claude analysis
- `debate_complete`: Submit Claude's analysis, get Codex counter + consensus

### Improvements

- Accurate model labeling
- Auto-detection of available AI providers
- Better error handling during streaming

### Breaking Changes

- None (streaming is opt-in via flags)
```
